import json

from flask import Blueprint, request, jsonify
import tempfile
import os
import sys
import shutil
import logging
from pathlib import Path
sys.path.append(str(Path(__file__).parent))
from .faiss_loader import load_documents_from_url
from .client_info_service import ClientInfoService
from .src.document_processor import DocumentProcessor, create_multimodal_processor, create_text_processor  # ‚úÖ –ù–û–í–´–ï –∏–º–ø–æ—Ä—Ç—ã
from .src.config import settings
import requests


bp = Blueprint('faiss', __name__)
logger = logging.getLogger(__name__)

try:
    from .src.search.smart_search import SmartSearchEngine, SearchConfig
    SMART_SEARCH_AVAILABLE = True
    print("‚úÖ –£–º–Ω—ã–π –ø–æ–∏—Å–∫ –¥–æ—Å—Ç—É–ø–µ–Ω")
except ImportError as e:
    SMART_SEARCH_AVAILABLE = False
    print(f"‚ö†Ô∏è –£–º–Ω—ã–π –ø–æ–∏—Å–∫ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")

@bp.route("/faiss/index", methods=["GET"])
def index():
    return {"status": "ok faiss index"}


@bp.route("/faiss/search", methods=["POST"])
def search():
    """–ü–æ–∏—Å–∫ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —É–º–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞"""
    try:
        data = request.json
        client_id = data.get("client_id")
        object_id = data.get("object_id")
        query = data.get("query", "")
        mode = data.get("mode", "auto")  # auto, normal, smart
        k = data.get("k", 5)

        if not client_id or not query:
            return jsonify({
                "status": "error",
                "error": "–¢—Ä–µ–±—É–µ—Ç—Å—è client_id –∏ query"
            }), 400

        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
        processor = DocumentProcessor(client_id=client_id)

        # ‚úÖ –ù–û–í–ê–Ø –õ–û–ì–ò–ö–ê: –í—ã–±–∏—Ä–∞–µ–º —Ä–µ–∂–∏–º –ø–æ–∏—Å–∫–∞
        if mode == "smart" and SMART_SEARCH_AVAILABLE:
            # –£–º–Ω—ã–π –ø–æ–∏—Å–∫
            config = SearchConfig(
                min_score_threshold=data.get("min_score", 0.3),
                semantic_weight=data.get("semantic_weight", 0.7),
                keyword_weight=data.get("keyword_weight", 0.3)
            )

            smart_searcher = SmartSearchEngine(processor, config)
            results = smart_searcher.smart_search(query, k=k)

            if object_id:
                results = [r for r in results if str(r.get("metadata", {}).get("object_id")) == str(object_id)]

            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è —É–º–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
            formatted_results = []
            for result in results:
                formatted_result = {
                    "chunk_id": result.get("chunk_id"),
                    "score": result.get("combined_score", result.get("score", 0)),
                    "search_type": "smart",
                    "text": result.get("text"),
                    "source_file": result.get("source_file"),
                    "metadata": result.get("metadata", {}),
                    "relevance_explanation": {
                        "original_score": result.get("original_score", 0),
                        "keyword_score": result.get("keyword_score", 0),
                        "intent_score": result.get("intent_score", 0),
                        "combined_score": result.get("combined_score", 0)
                    }
                }
                formatted_results.append(formatted_result)

            return jsonify({
                "status": "ok",
                "client_id": client_id,
                "query": query,
                "mode": "smart",
                "visual_search_enabled": getattr(processor, 'enable_visual_search', False),
                "results_count": len(formatted_results),
                "results": formatted_results
            })

        else:
            # –û–±—ã—á–Ω—ã–π –ø–æ–∏—Å–∫ (–∫–∞–∫ –±—ã–ª–æ)
            results = processor.search_documents(query, k=k)

            if object_id:
                results = [r for r in results if str(r.get("metadata", {}).get("object_id")) == str(object_id)]

            formatted_results = []
            for result in results:
                formatted_result = {
                    "chunk_id": result.get("chunk_id"),
                    "score": result.get("score", 0),
                    "search_type": "text",
                    "text": result.get("text"),
                    "source_file": result.get("source_file"),
                    "metadata": result.get("metadata", {})
                }
                formatted_results.append(formatted_result)

            return jsonify({
                "status": "ok",
                "client_id": client_id,
                "query": query,
                "mode": "normal",
                "visual_search_enabled": getattr(processor, 'enable_visual_search', False),
                "results_count": len(formatted_results),
                "results": formatted_results
            })

    except Exception as e:
        return jsonify({
            "status": "error",
            "error": str(e)
        }), 500



@bp.route("/faiss/create_index", methods=["POST"])
def create_index():
    """–°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ —Å –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º —Ä–µ–∂–∏–º–∞"""
    try:
        data = request.get_json()
        client_id = data["client_id"]
        enable_visual = True  # ‚úÖ –ù–û–í–û–ï: –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä

        clientData = "https://1c.gwd.ru/services/hs/Request/GetData/GetAllFiles?api_key=5939a5cc-948b-4d78-98a7-370193831b70&client_id=" + client_id

        result = load_documents_from_url(clientData, log_level="INFO")

        if result['success']:
            return {
                "status": "ok",
                "clientId": client_id,
                "visual_search_enabled": enable_visual,  # ‚úÖ –ù–û–í–û–ï
                "processed_documents": result['indexed'],
                "total_documents": result['total_documents'],
                "statistics": {
                    "downloaded": result['downloaded'],
                    "parsed": result['parsed'],
                    "chunked": result['chunked']
                }
            }
        return jsonify({
            "success": False,
            "error": result['error'],
            "error_type": "processing_error"
        }), 400

    except Exception as e:
        error_msg = f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {str(e)}"
        return jsonify({
            "success": False,
            "error": error_msg,
            "error_type": "internal_error"
        }), 500


@bp.route("/faiss/get_index", methods=["GET"])
def get_index():
    try:
        data = request.get_json()
        client_id = data["client_id"]

        # –°–æ–∑–¥–∞–µ–º —Å–µ—Ä–≤–∏—Å –∏ –ø–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        service = ClientInfoService()
        result = service.get_client_info(client_id)

        return jsonify(result)
    except KeyError:
        return jsonify({
            'success': False,
            'error': '–ù–µ —É–∫–∞–∑–∞–Ω client_id –≤ –∑–∞–ø—Ä–æ—Å–µ'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö: {str(e)}'
        })

@bp.route("/faiss/search_multimodal", methods=["POST"])
def search_multimodal():
    """–ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ç–µ–∫—Å—Ç–∞ –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
    try:
        data = request.json
        client_id = data.get("client_id")

        if not client_id:
            return jsonify({"error": "–¢—Ä–µ–±—É–µ—Ç—Å—è client_id"}), 400

        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä —Å –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º —Ä–µ–∂–∏–º–∞
        processor = DocumentProcessor(client_id=client_id)

        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∏—Å–∫–∞
        text_query = data.get("query")
        search_mode = data.get("mode", "text")  # "text", "visual_description", "multimodal"
        k = data.get("k", 5)
        min_score = data.get("min_score", 0.0)

        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–∂–∏–º–∞
        if search_mode == "text":
            results = processor.search_documents(
                query=text_query,
                k=k,
                min_score=min_score,
                search_mode="text"
            )

        elif search_mode == "visual_description" and processor.enable_visual_search:
            # –ü–æ–∏—Å–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É –æ–ø–∏—Å–∞–Ω–∏—é
            results = processor.search_by_text_description(
                text_description=text_query,
                k=k,
                search_images_only=True
            )

        else:
            return jsonify({
                "error": f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ä–µ–∂–∏–º –ø–æ–∏—Å–∫–∞: {search_mode}",
                "available_modes": ["text", "visual_description"] if processor.enable_visual_search else ["text"]
            }), 400

        return jsonify({
            "success": True,
            "client_id": client_id,
            "query": text_query,
            "mode": search_mode,
            "visual_search_available": processor.enable_visual_search,
            "results_count": len(results),
            "results": results
        })

    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@bp.route("/faiss/search_similar_images", methods=["POST"])
def search_similar_images():
    """–ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é"""
    try:
        client_id = request.form.get("client_id")
        if not client_id:
            return jsonify({"error": "–¢—Ä–µ–±—É–µ—Ç—Å—è client_id"}), 400

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        if 'image' not in request.files:
            return jsonify({"error": "–ù–µ–æ–±—Ö–æ–¥–∏–º–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"}), 400

        file = request.files['image']
        if file.filename == '':
            return jsonify({"error": "–§–∞–π–ª –Ω–µ –≤—ã–±—Ä–∞–Ω"}), 400

        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∏—Å–∫–∞
        k = int(request.form.get('k', 5))
        min_score = float(request.form.get('min_score', 0.0))

        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
        processor = DocumentProcessor(client_id=client_id)

        if not processor.enable_visual_search:
            return jsonify({
                "error": "–ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è —ç—Ç–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞",
                "suggestion": "–°–æ–∑–¥–∞–π—Ç–µ –∏–Ω–¥–µ–∫—Å —Å enable_visual_search=true"
            }), 503

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        with tempfile.NamedTemporaryFile(delete=False, suffix='.jpg') as temp_file:
            file.save(temp_file.name)
            temp_path = Path(temp_file.name)

        try:
            # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            results = processor.search_similar_images(
                query_image_path=temp_path,
                k=k,
                min_score=min_score
            )

            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            analysis = processor.get_image_analysis(temp_path)

            return jsonify({
                "success": True,
                "client_id": client_id,
                "uploaded_image_analysis": analysis,
                "similar_images_count": len(results),
                "similar_images": results
            })

        finally:
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            temp_path.unlink(missing_ok=True)

    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@bp.route("/faiss/search_by_description", methods=["POST"])
def search_by_description():
    """–ü–æ–∏—Å–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É –æ–ø–∏—Å–∞–Ω–∏—é"""
    try:
        data = request.json
        client_id = data.get("client_id")
        description = data.get("description")

        if not client_id or not description:
            return jsonify({"error": "–¢—Ä–µ–±—É—é—Ç—Å—è client_id –∏ description"}), 400

        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
        processor = DocumentProcessor(client_id=client_id)

        if not processor.enable_visual_search:
            # Fallback –Ω–∞ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫
            results = processor.search_documents(description, k=data.get("k", 5))
            search_mode = "text_fallback"
        else:
            # –í–∏–∑—É–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –æ–ø–∏—Å–∞–Ω–∏—é
            results = processor.search_by_text_description(
                text_description=description,
                k=data.get("k", 5),
                search_images_only=data.get("images_only", True)
            )
            search_mode = "visual_description"

        return jsonify({
            "success": True,
            "client_id": client_id,
            "description": description,
            "search_mode": search_mode,
            "visual_search_available": processor.enable_visual_search,
            "results_count": len(results),
            "results": results
        })

    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


@bp.route("/faiss/analyze_image", methods=["POST"])
def analyze_image():
    """–ê–Ω–∞–ª–∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é CLIP"""
    try:
        client_id = request.form.get("client_id", "temp")

        if 'image' not in request.files:
            return jsonify({"error": "–ù–µ–æ–±—Ö–æ–¥–∏–º–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"}), 400

        file = request.files['image']

        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
        try:
            processor = create_multimodal_processor(client_id)
        except Exception as e:
            return jsonify({
                "error": "–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω",
                "details": str(e),
                "suggestion": "–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã torch –∏ CLIP"
            }), 503

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        with tempfile.NamedTemporaryFile(delete=False, suffix='.jpg') as temp_file:
            file.save(temp_file.name)
            temp_path = Path(temp_file.name)

        try:
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            analysis = processor.get_image_analysis(temp_path)

            return jsonify({
                "success": True,
                "filename": file.filename,
                "analysis": analysis
            })

        finally:
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            temp_path.unlink(missing_ok=True)

    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


@bp.route("/faiss/client_capabilities", methods=["GET"])
def get_client_capabilities():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –ø–æ–∏—Å–∫–∞ –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞"""
    try:
        client_id = request.args.get("client_id")
        if not client_id:
            return jsonify({"error": "–¢—Ä–µ–±—É–µ—Ç—Å—è client_id"}), 400

        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä —Å –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º —Ä–µ–∂–∏–º–∞
        processor = DocumentProcessor(client_id=client_id)

        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–µ–∂–∏–º–µ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        mode_info = processor.get_processing_mode_info()
        stats = processor.get_index_statistics()

        return jsonify({
            "success": True,
            "client_id": client_id,
            "processing_mode": mode_info,
            "capabilities": mode_info['capabilities'],
            "statistics": {
                'total_chunks': stats.get('total_chunks', 0),
                'text_vectors': stats.get('text_vectors_count', stats.get('total_vectors', 0)),
                'visual_vectors': stats.get('visual_vectors_count', 0),
                'images_count': stats.get('content_analysis', {}).get('images_count', 0),
                'documents_count': stats.get('content_analysis', {}).get('documents_count', 0),
                'visual_coverage': stats.get('content_analysis', {}).get('visual_coverage', 0)
            },
            "available_search_modes": [
                "text_search",
                "image_search_by_description",
                "similar_image_search",
                "multimodal_combined_search",
                "image_analysis"
            ] if mode_info['visual_search_enabled'] else ["text_search"]
        })

    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


@bp.route("/faiss/create_multimodal_index", methods=["POST"])
def create_multimodal_index():
    """–°–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—ã–π –∏–Ω–¥–µ–∫—Å —Å —è–≤–Ω–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–∏"""
    try:
        data = request.json
        client_id = data["client_id"]
        enable_visual = True

        # URL –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö
        client_data_url = f"https://1c.gwd.ru/services/hs/Request/GetData/GetAllFiles?api_key=5939a5cc-948b-4d78-98a7-370193831b70&client_id={client_id}"

        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä —Å –Ω—É–∂–Ω—ã–º —Ä–µ–∂–∏–º–æ–º
        if enable_visual:
            try:
                processor = create_multimodal_processor(client_id)
            except Exception as e:
                return jsonify({
                    "success": False,
                    "error": f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä: {str(e)}",
                    "suggestion": "–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã torch –∏ CLIP"
                }), 503
        else:
            processor = create_text_processor(client_id)

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
        from .faiss_loader import DocumentLoader
        loader = DocumentLoader()

        # –ó–∞–≥—Ä—É–∂–∞–µ–º JSON –¥–∞–Ω–Ω—ã–µ
        json_data, extracted_client_id = loader.download_json_data(client_data_url)
        json_path = loader.save_json_data(json_data, extracted_client_id)

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
        result = processor.process_documents_from_json(json_path)

        if result['success']:
            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            stats = processor.get_index_statistics()
            mode_info = processor.get_processing_mode_info()

            return jsonify({
                "status": "ok",
                "client_id": client_id,
                "multimodal_enabled": enable_visual,
                "processed_documents": result['indexed'],
                "statistics": {
                    "downloaded": result['downloaded'],
                    "parsed": result['parsed'],
                    "chunked": result['chunked'],
                    "images_processed": result.get('images_processed', 0),
                    "visual_vectors_created": result.get('visual_vectors_created', 0),
                    "text_vectors_created": result.get('text_vectors_created', 0)
                },
                "index_stats": stats,
                "capabilities": mode_info['capabilities']
            })
        else:
            return jsonify({
                "success": False,
                "error": result.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞'),
                "details": result
            }), 400

    except Exception as e:
        return jsonify({
            "success": False,
            "error": f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞: {str(e)}"
        }), 500

@bp.route("/faiss/delete_client", methods=["POST"])
def delete_client():
    """
    –≠–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–∞
    –û—Å–Ω–æ–≤–∞–Ω –Ω–∞ –ª–æ–≥–∏–∫–µ quick_cleanup.py

    –ü—Ä–∏–Ω–∏–º–∞–µ—Ç JSON: {"client_id": "xxx"}
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —É–¥–∞–ª–µ–Ω–∏—è
    """
    try:
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
        data = request.get_json()
        if not data or 'client_id' not in data:
            return jsonify({
                'success': False,
                'error': '–ù–µ —É–∫–∞–∑–∞–Ω client_id –≤ –∑–∞–ø—Ä–æ—Å–µ',
                'error_type': 'missing_parameter'
            }), 400

        client_id = data['client_id']
        logger.info(f"üßπ –ó–∞–ø—Ä–æ—Å –Ω–∞ —É–¥–∞–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–∞: {client_id}")

        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è —ç—Ç–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞
        processor = DocumentProcessor(client_id=client_id)

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç–∏ –∫ –¥–∞–Ω–Ω—ã–º –∫–ª–∏–µ–Ω—Ç–∞ (–∫–∞–∫ –≤ quick_cleanup.py)
        client_docs_path = settings.CLIENTS_DIR / client_id / "documents"
        client_faiss_path = settings.FAISS_INDEX_DIR / "clients" / client_id

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        if not client_docs_path.exists() and not client_faiss_path.exists():
            return jsonify({
                'success': False,
                'error': f'–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞ {client_id}',
                'error_type': 'client_not_found',
                'searched_paths': {
                    'documents': str(client_docs_path),
                    'faiss_index': str(client_faiss_path)
                }
            }), 404

        # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –î–û —É–¥–∞–ª–µ–Ω–∏—è
        stats_before = {}
        try:
            index_stats = processor.get_index_statistics()
            stats_before = {
                'documents_in_index': index_stats.get('sources_count', 0),
                'chunks_in_index': index_stats.get('total_chunks', 0),
                'vectors_in_index': index_stats.get('total_vectors', 0)
            }
        except Exception:
            # –ï—Å–ª–∏ –∏–Ω–¥–µ–∫—Å –ø–æ–≤—Ä–µ–∂–¥–µ–Ω –∏–ª–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è
            stats_before = {'index_error': '–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–Ω–¥–µ–∫—Å–∞'}

        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª—ã –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
        downloaded_files = list(client_docs_path.glob("**/*")) if client_docs_path.exists() else []
        faiss_files = list(client_faiss_path.glob("*")) if client_faiss_path.exists() else []

        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö
        docs_size = sum(f.stat().st_size for f in downloaded_files if f.is_file()) / 1024 / 1024
        faiss_size = sum(f.stat().st_size for f in faiss_files if f.is_file()) / 1024 / 1024
        total_size_mb = docs_size + faiss_size

        deletion_stats = {
            'files_to_delete': len(downloaded_files),
            'index_files_to_delete': len(faiss_files),
            'estimated_size_mb': round(total_size_mb, 2)
        }

        logger.info(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–µ—Ä–µ–¥ —É–¥–∞–ª–µ–Ω–∏–µ–º –¥–ª—è {client_id}: {deletion_stats}")

        # –í—ã–ø–æ–ª–Ω—è–µ–º —É–¥–∞–ª–µ–Ω–∏–µ
        removed_files = 0
        removed_index_files = 0
        errors = []

        # 1. –£–¥–∞–ª—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –∫–ª–∏–µ–Ω—Ç–∞
        if client_docs_path.exists():
            try:
                shutil.rmtree(client_docs_path)
                removed_files = len(downloaded_files)
                logger.info(f"‚úÖ –£–¥–∞–ª–µ–Ω—ã –¥–æ–∫—É–º–µ–Ω—Ç—ã –∫–ª–∏–µ–Ω—Ç–∞: {removed_files} —Ñ–∞–π–ª–æ–≤")
            except Exception as e:
                error_msg = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {str(e)}"
                errors.append(error_msg)
                logger.error(error_msg)

        # 2. –£–¥–∞–ª—è–µ–º FAISS –∏–Ω–¥–µ–∫—Å –∫–ª–∏–µ–Ω—Ç–∞
        if client_faiss_path.exists():
            try:
                shutil.rmtree(client_faiss_path)
                removed_index_files = len(faiss_files)
                logger.info(f"‚úÖ –£–¥–∞–ª–µ–Ω FAISS –∏–Ω–¥–µ–∫—Å –∫–ª–∏–µ–Ω—Ç–∞: {removed_index_files} —Ñ–∞–π–ª–æ–≤")
            except Exception as e:
                error_msg = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –∏–Ω–¥–µ–∫—Å–∞: {str(e)}"
                errors.append(error_msg)
                logger.error(error_msg)

        # 3. –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ (–µ—Å–ª–∏ —á—Ç–æ-—Ç–æ –æ—Å—Ç–∞–ª–æ—Å—å)
        try:
            if not errors:  # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ —É–¥–∞–ª–µ–Ω–∏–µ –ø—Ä–æ—à–ª–æ —É—Å–ø–µ—à–Ω–æ
                processor.clear_all_data()
                logger.info("‚úÖ –í—ã–ø–æ–ª–Ω–µ–Ω–∞ –ø—Ä–æ–≥—Ä–∞–º–º–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –∏–Ω–¥–µ–∫—Å–∞")
        except Exception as e:
            # –≠—Ç–æ –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–æ, —Ç–∞–∫ –∫–∞–∫ —Ñ–∞–π–ª—ã —É–∂–µ —É–¥–∞–ª–µ–Ω—ã
            logger.warning(f"‚ö†Ô∏è –ü—Ä–æ–≥—Ä–∞–º–º–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞: {str(e)}")

        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        success = len(errors) == 0
        result = {
            'success': success,
            'client_id': client_id,
            'stats_before': stats_before,
            'deletion_summary': {
                'removed_document_files': removed_files,
                'removed_index_files': removed_index_files,
                'freed_space_mb': round(total_size_mb, 2)
            },
            'message': f"–î–∞–Ω–Ω—ã–µ –∫–ª–∏–µ–Ω—Ç–∞ {client_id} {'—É—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω—ã' if success else '—á–∞—Å—Ç–∏—á–Ω–æ —É–¥–∞–ª–µ–Ω—ã'}"
        }

        if errors:
            result['errors'] = errors
            result['warning'] = '–£–¥–∞–ª–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–∏–ª–æ—Å—å —Å –æ—à–∏–±–∫–∞–º–∏'

        status_code = 200 if success else 207  # 207 = Multi-Status (—á–∞—Å—Ç–∏—á–Ω—ã–π —É—Å–ø–µ—Ö)

        logger.info(f"üéâ –£–¥–∞–ª–µ–Ω–∏–µ –¥–ª—è {client_id} –∑–∞–≤–µ—Ä—à–µ–Ω–æ: {'—É—Å–ø–µ—à–Ω–æ' if success else '—Å –æ—à–∏–±–∫–∞–º–∏'}")

        return jsonify(result), status_code

    except Exception as e:
        error_msg = f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–∞: {str(e)}"
        logger.error(error_msg)
        return jsonify({
            'success': False,
            'error': error_msg,
            'error_type': 'internal_error'
        }), 500

@bp.route("/faiss/update_client", methods=["POST"])
def update_client():
    """
    –û–±–Ω–æ–≤–ª—è–µ—Ç –∫–ª–∏–µ–Ω—Ç–∞: –≤—ã–∑—ã–≤–∞–µ—Ç /faiss/delete_client –∏ /faiss/create_multimodal_index
    """
    try:
        data = request.get_json()
        client_id = data.get("client_id")
        enable_visual = True

        if not client_id:
            return jsonify({"success": False, "error": "client_id –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω"}), 400

        base_url = "http://localhost:8000/faiss"  # ‚ö†Ô∏è —Å–º–æ—Ç—Ä–∏ —á—Ç–æ–±—ã —Å–æ–≤–ø–∞–¥–∞–ª–æ —Å —Ç–≤–æ–∏–º —Ö–æ—Å—Ç–æ–º/–ø–æ—Ä—Ç–æ–º

        # 1. –£–¥–∞–ª–µ–Ω–∏–µ
        delete_resp = requests.post(f"{base_url}/delete_client", json={"client_id": client_id})
        delete_json = delete_resp.json()

        # 2. –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞
        create_resp = requests.post(f"{base_url}/create_multimodal_index", json={
            "client_id": client_id,
            "enable_visual_search": enable_visual
        })
        create_json = create_resp.json()

        return jsonify({
            "success": True,
            "client_id": client_id,
            "delete_phase": delete_json,
            "create_phase": create_json,
            "message": f"–ö–ª–∏–µ–Ω—Ç {client_id} —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª—ë–Ω"
        }), 200

    except Exception as e:
        return jsonify({
            "success": False,
            "error": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –∫–ª–∏–µ–Ω—Ç–∞: {e}"
        }), 500


@bp.route("/faiss/find_similar_to_existing", methods=["POST"])
def find_similar_to_existing():
    """–ü–æ–∏—Å–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –ø–æ—Ö–æ–∂–∏—Ö –Ω–∞ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–µ –≤ –∏–Ω–¥–µ–∫—Å–µ"""
    try:
        data = request.json
        client_id = data.get("client_id")
        source_file = data.get("source_file")
        k = data.get("k", 5)

        if not client_id or not source_file:
            return jsonify({"error": "–¢—Ä–µ–±—É—é—Ç—Å—è client_id –∏ source_file"}), 400

        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
        processor = DocumentProcessor(client_id=client_id)

        if not processor.enable_visual_search:
            return jsonify({
                "error": "–í–∏–∑—É–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è —ç—Ç–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞",
                "suggestion": "–°–æ–∑–¥–∞–π—Ç–µ –∏–Ω–¥–µ–∫—Å —Å enable_visual_search=true"
            }), 503

        # –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ
        results = processor.get_similar_to_existing(source_file, k=k)

        return jsonify({
            "success": True,
            "client_id": client_id,
            "source_file": source_file,
            "similar_images_count": len(results),
            "similar_images": results
        })

    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


@bp.route("/faiss/search_combined", methods=["POST"])
def search_combined():
    """–ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ (—Ç–µ–∫—Å—Ç + –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ)"""
    try:
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–æ—Ä–º—ã (–¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞) –∏ JSON
        client_id = request.form.get("client_id")
        text_query = request.form.get("text_query")
        text_weight = float(request.form.get("text_weight", 0.6))
        k = int(request.form.get("k", 5))

        if not client_id:
            return jsonify({"error": "–¢—Ä–µ–±—É–µ—Ç—Å—è client_id"}), 400

        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
        processor = DocumentProcessor(client_id=client_id)

        if not processor.enable_visual_search:
            # Fallback –Ω–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫
            if text_query:
                results = processor.search_documents(text_query, k=k)
                return jsonify({
                    "success": True,
                    "client_id": client_id,
                    "search_mode": "text_only_fallback",
                    "results": results
                })
            else:
                return jsonify({"error": "–ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, —Ç—Ä–µ–±—É–µ—Ç—Å—è text_query"}), 400

        image_query_path = None

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –µ—Å–ª–∏ –µ—Å—Ç—å
        if 'image' in request.files:
            file = request.files['image']
            if file.filename != '':
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                with tempfile.NamedTemporaryFile(delete=False, suffix='.jpg') as temp_file:
                    file.save(temp_file.name)
                    image_query_path = temp_file.name

        try:
            # –í—ã–ø–æ–ª–Ω—è–µ–º –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–∏—Å–∫
            results = processor.search_multimodal(
                text_query=text_query,
                image_query_path=image_query_path,
                k=k,
                text_weight=text_weight
            )

            return jsonify({
                "success": True,
                "client_id": client_id,
                "text_query": text_query,
                "has_image_query": image_query_path is not None,
                "text_weight": text_weight,
                "search_mode": "multimodal_combined",
                "results_count": len(results),
                "results": results
            })

        finally:
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            if image_query_path:
                Path(image_query_path).unlink(missing_ok=True)

    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


@bp.route("/faiss/export_visual_vectors", methods=["POST"])
def export_visual_vectors():
    """–≠–∫—Å–ø–æ—Ä—Ç –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤ –∫–ª–∏–µ–Ω—Ç–∞"""
    try:
        data = request.json
        client_id = data.get("client_id")

        if not client_id:
            return jsonify({"error": "–¢—Ä–µ–±—É–µ—Ç—Å—è client_id"}), 400

        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
        processor = DocumentProcessor(client_id=client_id)

        if not processor.enable_visual_search:
            return jsonify({
                "error": "–í–∏–∑—É–∞–ª—å–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä—ã –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã –¥–ª—è —ç—Ç–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞"
            }), 400

        # –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –≤–µ–∫—Ç–æ—Ä—ã
        export_data = processor.faiss_manager.export_visual_vectors()

        if 'error' in export_data:
            return jsonify({
                "success": False,
                "error": export_data['error']
            }), 400

        return jsonify({
            "success": True,
            "client_id": client_id,
            "export_data": export_data
        })

    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ endpoint'—ã –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞

@bp.route("/faiss/health_check", methods=["GET"])
def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞"""
    try:
        from .src.data.image_processor import CLIP_AVAILABLE, OCR_AVAILABLE, check_dependencies

        dependencies = check_dependencies()

        return jsonify({
            "success": True,
            "system_status": "healthy",
            "dependencies": dependencies,
            "features_available": {
                "text_search": True,
                "visual_search": dependencies['clip_available'],
                "ocr_processing": dependencies['ocr_available'],
                "gpu_acceleration": dependencies['cuda_available']
            }
        })

    except Exception as e:
        return jsonify({
            "success": False,
            "system_status": "unhealthy",
            "error": str(e)
        }), 500

@bp.route("/faiss/materials", methods=["GET"])
def get_materials():
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤"""
    try:
        client_id = request.args.get('client_id')
        page = int(request.args.get('page', 1))
        per_page = int(request.args.get('per_page', 50))
        source_file = request.args.get('source_file')  # –§–∏–ª—å—Ç—Ä –ø–æ —Ñ–∞–π–ª—É
        category = request.args.get('category')  # –§–∏–ª—å—Ç—Ä –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏

        if not client_id:
            return jsonify({
                "status": "error",
                "error": "–¢—Ä–µ–±—É–µ—Ç—Å—è client_id"
            }), 400

        processor = DocumentProcessor(client_id=client_id)

        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —á–∞–Ω–∫–∏
        all_chunks = processor.faiss_manager.get_all_chunks()

        if not all_chunks:
            return jsonify({
                "status": "ok",
                "client_id": client_id,
                "total_chunks": 0,
                "materials": [],
                "pagination": {
                    "page": page,
                    "per_page": per_page,
                    "total_pages": 0
                }
            })

        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã
        filtered_chunks = all_chunks

        if source_file:
            filtered_chunks = [chunk for chunk in filtered_chunks
                               if chunk.get('source_file', '').lower() == source_file.lower()]

        if category:
            filtered_chunks = [chunk for chunk in filtered_chunks
                               if chunk.get('metadata', {}).get('category', '').lower() == category.lower()]

        # –ü–∞–≥–∏–Ω–∞—Ü–∏—è
        total_chunks = len(filtered_chunks)
        total_pages = (total_chunks + per_page - 1) // per_page
        start_idx = (page - 1) * per_page
        end_idx = start_idx + per_page
        paginated_chunks = filtered_chunks[start_idx:end_idx]

        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Ç–≤–µ—Ç–∞
        materials = []
        for chunk in paginated_chunks:
            metadata = chunk.get('metadata', {})
            material = {
                "chunk_id": chunk.get('chunk_id'),
                "source_file": chunk.get('source_file'),
                "chunk_index": metadata.get('chunk_index', 0),
                "text_preview": chunk.get('text', '')[:200] + ("..." if len(chunk.get('text', '')) > 200 else ''),
                "text_length": len(chunk.get('text', '')),
                "metadata": {
                    "title": metadata.get('title'),
                    "description": metadata.get('description'),
                    "category": metadata.get('category'),
                    "parent": metadata.get('parent'),
                    "date": metadata.get('date'),
                    "file_type": metadata.get('file_type'),
                    "file_size": metadata.get('file_size'),
                    "source_url": metadata.get('source_url'),
                    "processing_date": metadata.get('processing_date'),
                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
                    "is_image": metadata.get('file_type', '').lower() in ['.jpg', '.jpeg', '.png', '.gif', '.bmp'],
                    "has_visual_embedding": metadata.get('has_visual_embedding', False),
                    "image_width": metadata.get('image_width'),
                    "image_height": metadata.get('image_height')
                }
            }
            materials.append(material)

        return jsonify({
            "status": "ok",
            "client_id": client_id,
            "total_chunks": total_chunks,
            "filtered_chunks": len(filtered_chunks),
            "materials": materials,
            "pagination": {
                "page": page,
                "per_page": per_page,
                "total_pages": total_pages,
                "has_next": page < total_pages,
                "has_prev": page > 1
            },
            "filters": {
                "source_file": source_file,
                "category": category
            }
        })

    except Exception as e:
        return jsonify({
            "status": "error",
            "error": str(e)
        }), 500


@bp.route("/faiss/materials/summary", methods=["GET"])
def get_materials_summary():
    """–ü–æ–ª—É—á–∏—Ç—å —Å–≤–æ–¥–∫—É –ø–æ –º–∞—Ç–µ—Ä–∏–∞–ª–∞–º (—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞, –∫–∞—Ç–µ–≥–æ—Ä–∏–∏, —Ñ–∞–π–ª—ã)"""
    try:
        client_id = request.args.get('client_id')

        if not client_id:
            return jsonify({
                "status": "error",
                "error": "–¢—Ä–µ–±—É–µ—Ç—Å—è client_id"
            }), 400

        processor = DocumentProcessor(client_id=client_id)

        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–Ω–¥–µ–∫—Å–∞
        stats = processor.get_index_statistics()

        if stats.get('status') != 'ready':
            return jsonify({
                "status": "ok",
                "client_id": client_id,
                "index_status": stats.get('status', 'not_ready'),
                "summary": None
            })

        all_chunks = processor.faiss_manager.get_all_chunks()

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã
        files_info = {}
        categories_info = {}
        file_types_info = {}

        for chunk in all_chunks:
            metadata = chunk.get('metadata', {})
            source_file = chunk.get('source_file', 'unknown')
            category = metadata.get('category', 'uncategorized')
            file_type = metadata.get('file_type', 'unknown')

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ñ–∞–π–ª–∞–º
            if source_file not in files_info:
                files_info[source_file] = {
                    "chunks_count": 0,
                    "total_characters": 0,
                    "file_type": file_type,
                    "category": category,
                    "title": metadata.get('title', ''),
                    "description": metadata.get('description', ''),
                    "date": metadata.get('date', ''),
                    "file_size": metadata.get('file_size', 0),
                    "source_url": metadata.get('source_url', ''),
                    "is_image": file_type.lower() in ['.jpg', '.jpeg', '.png', '.gif', '.bmp'],
                    "has_visual_embedding": metadata.get('has_visual_embedding', False)
                }

            files_info[source_file]["chunks_count"] += 1
            files_info[source_file]["total_characters"] += len(chunk.get('text', ''))

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
            if category not in categories_info:
                categories_info[category] = {
                    "files_count": 0,
                    "chunks_count": 0,
                    "file_types": set()
                }

            if source_file not in [f["source_file"] for f in categories_info[category].get("files", [])]:
                categories_info[category]["files_count"] += 1

            categories_info[category]["chunks_count"] += 1
            categories_info[category]["file_types"].add(file_type)

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º —Ñ–∞–π–ª–æ–≤
            if file_type not in file_types_info:
                file_types_info[file_type] = {
                    "files_count": 0,
                    "chunks_count": 0,
                    "total_size": 0
                }

            if source_file not in [f for f in files_info.keys() if files_info[f]["file_type"] == file_type]:
                file_types_info[file_type]["files_count"] += 1
                file_types_info[file_type]["total_size"] += metadata.get('file_size', 0)

            file_types_info[file_type]["chunks_count"] += 1

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º sets –≤ lists –¥–ª—è JSON
        for category in categories_info:
            categories_info[category]["file_types"] = list(categories_info[category]["file_types"])

        summary = {
            "overview": {
                "total_files": len(files_info),
                "total_chunks": len(all_chunks),
                "total_categories": len(categories_info),
                "total_file_types": len(file_types_info),
                "images_count": sum(1 for f in files_info.values() if f["is_image"]),
                "documents_count": sum(1 for f in files_info.values() if not f["is_image"]),
                "visual_embeddings_count": sum(1 for f in files_info.values() if f["has_visual_embedding"])
            },
            "files": files_info,
            "categories": categories_info,
            "file_types": file_types_info,
            "index_stats": stats
        }

        return jsonify({
            "status": "ok",
            "client_id": client_id,
            "index_status": "ready",
            "summary": summary
        })

    except Exception as e:
        return jsonify({
            "status": "error",
            "error": str(e)
        }), 500


@bp.route("/faiss/materials/file/<path:filename>", methods=["GET"])
def get_file_materials(filename):
    """–ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ —á–∞–Ω–∫–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ñ–∞–π–ª–∞"""
    try:
        client_id = request.args.get('client_id')

        if not client_id:
            return jsonify({
                "status": "error",
                "error": "–¢—Ä–µ–±—É–µ—Ç—Å—è client_id"
            }), 400

        processor = DocumentProcessor(client_id=client_id)
        file_chunks = processor.faiss_manager.get_chunks_by_source(filename)

        if not file_chunks:
            return jsonify({
                "status": "ok",
                "client_id": client_id,
                "filename": filename,
                "chunks_count": 0,
                "chunks": [],
                "file_info": None
            })

        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–µ –∏–∑ –ø–µ—Ä–≤–æ–≥–æ —á–∞–Ω–∫–∞
        first_chunk = file_chunks[0]
        metadata = first_chunk.get('metadata', {})

        file_info = {
            "filename": filename,
            "title": metadata.get('title'),
            "description": metadata.get('description'),
            "category": metadata.get('category'),
            "parent": metadata.get('parent'),
            "date": metadata.get('date'),
            "file_type": metadata.get('file_type'),
            "file_size": metadata.get('file_size'),
            "source_url": metadata.get('source_url'),
            "processing_date": metadata.get('processing_date'),
            "is_image": metadata.get('file_type', '').lower() in ['.jpg', '.jpeg', '.png', '.gif', '.bmp'],
            "has_visual_embedding": metadata.get('has_visual_embedding', False),
            "total_chunks": len(file_chunks),
            "total_characters": sum(len(chunk.get('text', '')) for chunk in file_chunks)
        }

        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —á–∞–Ω–∫–∏
        formatted_chunks = []
        for chunk in file_chunks:
            formatted_chunk = {
                "chunk_id": chunk.get('chunk_id'),
                "chunk_index": chunk.get('metadata', {}).get('chunk_index', 0),
                "text": chunk.get('text'),
                "text_length": len(chunk.get('text', '')),
                "start_char": chunk.get('metadata', {}).get('start_char', 0),
                "end_char": chunk.get('metadata', {}).get('end_char', 0),
                "chunk_size": chunk.get('metadata', {}).get('chunk_size', 0)
            }
            formatted_chunks.append(formatted_chunk)

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∏–Ω–¥–µ–∫—Å—É —á–∞–Ω–∫–∞
        formatted_chunks.sort(key=lambda x: x['chunk_index'])

        return jsonify({
            "status": "ok",
            "client_id": client_id,
            "filename": filename,
            "chunks_count": len(file_chunks),
            "file_info": file_info,
            "chunks": formatted_chunks
        })

    except Exception as e:
        return jsonify({
            "status": "error",
            "error": str(e)
        }), 500


@bp.route("/faiss/materials/categories", methods=["GET"])
def get_categories():
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤"""
    try:
        client_id = request.args.get('client_id')

        if not client_id:
            return jsonify({
                "status": "error",
                "error": "–¢—Ä–µ–±—É–µ—Ç—Å—è client_id"
            }), 400

        processor = DocumentProcessor(client_id=client_id)
        all_chunks = processor.faiss_manager.get_all_chunks()

        categories = {}
        files_by_category = {}

        for chunk in all_chunks:
            metadata = chunk.get('metadata', {})
            category = metadata.get('category', 'uncategorized')
            source_file = chunk.get('source_file', 'unknown')

            if category not in categories:
                categories[category] = {
                    "chunks_count": 0,
                    "files": set(),
                    "file_types": set()
                }
                files_by_category[category] = set()

            categories[category]["chunks_count"] += 1
            categories[category]["files"].add(source_file)
            categories[category]["file_types"].add(metadata.get('file_type', 'unknown'))
            files_by_category[category].add(source_file)

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º sets –≤ lists –∏ –¥–æ–±–∞–≤–ª—è–µ–º counts
        formatted_categories = []
        for category, info in categories.items():
            formatted_categories.append({
                "category": category,
                "chunks_count": info["chunks_count"],
                "files_count": len(info["files"]),
                "files": list(info["files"]),
                "file_types": list(info["file_types"])
            })

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Ñ–∞–π–ª–æ–≤
        formatted_categories.sort(key=lambda x: x['files_count'], reverse=True)

        return jsonify({
            "status": "ok",
            "client_id": client_id,
            "total_categories": len(formatted_categories),
            "categories": formatted_categories
        })

    except Exception as e:
        return jsonify({
            "status": "error",
            "error": str(e)
        }), 500


@bp.route("/faiss/materials/delete", methods=["DELETE"])
def delete_material():
    """–£–¥–∞–ª–∏—Ç—å –º–∞—Ç–µ—Ä–∏–∞–ª –∏–∑ –∏–Ω–¥–µ–∫—Å–∞"""
    try:
        data = request.json
        client_id = data.get('client_id')
        source_file = data.get('source_file')
        chunk_id = data.get('chunk_id')  # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ - —É–¥–∞–ª–∏—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —á–∞–Ω–∫

        if not client_id:
            return jsonify({
                "status": "error",
                "error": "–¢—Ä–µ–±—É–µ—Ç—Å—è client_id"
            }), 400

        if not source_file and not chunk_id:
            return jsonify({
                "status": "error",
                "error": "–¢—Ä–µ–±—É–µ—Ç—Å—è source_file –∏–ª–∏ chunk_id"
            }), 400

        processor = DocumentProcessor(client_id=client_id)

        if chunk_id:
            # –£–¥–∞–ª—è–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —á–∞–Ω–∫
            success = processor.faiss_manager.remove_chunks([chunk_id])
            if success:
                processor.faiss_manager.save_index()
                return jsonify({
                    "status": "ok",
                    "message": f"–ß–∞–Ω–∫ {chunk_id} —É–¥–∞–ª–µ–Ω",
                    "deleted_chunks": 1
                })
            else:
                return jsonify({
                    "status": "error",
                    "error": "–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å —á–∞–Ω–∫"
                }), 500

        elif source_file:
            # –£–¥–∞–ª—è–µ–º –≤–µ—Å—å —Ñ–∞–π–ª
            success = processor.remove_document(source_file)
            if success:
                return jsonify({
                    "status": "ok",
                    "message": f"–§–∞–π–ª {source_file} —É–¥–∞–ª–µ–Ω –∏–∑ –∏–Ω–¥–µ–∫—Å–∞"
                })
            else:
                return jsonify({
                    "status": "error",
                    "error": "–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å"
                }), 404

    except Exception as e:
        return jsonify({
            "status": "error",
            "error": str(e)
        }), 500


@bp.route("/faiss/system_info", methods=["GET"])
def system_info():
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–∏—Å—Ç–µ–º–µ –∏ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è—Ö"""
    try:
        from .src.data.image_processor import check_dependencies
        from .src.config import settings

        dependencies = check_dependencies()

        return jsonify({
            "success": True,
            "system_info": {
                "text_model": settings.EMBEDDING_MODEL,
                "visual_model": settings.CLIP_MODEL if dependencies['clip_available'] else None,
                "text_dimension": settings.EMBEDDING_DIMENSION,
                "visual_dimension": settings.VISUAL_EMBEDDING_DIMENSION,
                "device": settings.get_device_for_processing(),
                "keep_files": settings.KEEP_DOWNLOADED_FILES,
                "visual_search_default": settings.ENABLE_VISUAL_SEARCH_BY_DEFAULT
            },
            "dependencies": dependencies,
            "supported_features": {
                "text_search": True,
                "visual_search": dependencies['clip_available'],
                "multimodal_search": dependencies['clip_available'],
                "image_analysis": dependencies['clip_available'],
                "ocr_processing": dependencies['ocr_available']
            }
        })

    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500